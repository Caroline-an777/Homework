# 基于三层神经网络实现 CIFAR-10 图像分类
## 项目概述
本项目实现了一个基于CIFAR-10数据集的三层神经网络，包含数据加载、模型定义、训练、超参数优化、测试及可视化功能。代码采用纯NumPy实现，无深度学习框架依赖，在CIFAR-10数据集上达到约47-52%的测试准确率。
## 功能特点
- 数据处理：自动下载CIFAR-10数据集，支持数据标准化及训练/验证集划分。
- 模型架构：实现ReLU/Sigmoid激活函数的三层神经网络，支持正则化。
- 训练流程：包含批量训练、学习率衰减及早停机制。
- 超参数优化：支持网格搜索，自动记录最佳模型。
- 可视化：生成训练曲线及超参数对比图。
- 模块化设计：6个独立模块
## 数据集
CIFAR-10 数据集包含：
- 60,000张32x32彩色图像
- 10个类别（飞机、汽车、鸟类等）
- 数据划分：
  - 训练集：45,000
  - 验证集：5,000
  - 测试集：10,000
## 项目结构
```text
cifar10-classifier/
├── utils.py      # 数据下载与预处理
├── model.py           # 神经网络模型定义
├── train.py           # 训练流程控制
├── test.py            # 测试评估模块
├── search.py # 超参数搜索
├── visualize.py   # 结果可视化
└── main.py            # 主程序入口
```
## 安装依赖
```bash
pip install numpy scikit-learn matplotlib
```
## 运行程序
```bash
python main.py
```
## 实现细节
### 1.数据处理
- 自动下载CIFAR-10数据集（约163MB），支持断点续传。
- 数据标准化：对训练集、验证集和测试集分别进行Z-Score标准化。
- 数据集划分：从完整训练集中划分出验证集（默认10%）.
### 2.模型架构
- 实现三层神经网络。
 ```bash
  输入层(3072) → 隐藏层(256/512) → 输出层(10)
 ```
- 支持两种激活函数：ReLU 和 Sigmoid。
- 使用He初始化方法初始化网络权重
- Softmax输出层
### 3.训练流程
- 批量训练：支持小批量梯度下降（默认批次大小128）。
- 学习率衰减：每固定轮数（默认10轮）衰减学习率（默认衰减率0.95）。
- 正则化：支持L2正则化，防止过拟合。
- 早停机制：保存验证集上表现最佳的模型参数。
### 4.超参数优化
- 网格搜索：支持多种超参数组合的自动搜索。
- 参数范围：
  - 隐藏层维度：[128,256,512,1024]
  - 学习率：[0.1,0.05,0.01,0.005,0.001]
  - 正则化强度：[0.01,0.005,0.001]
  - 激活函数：['ReLU','Sigmoid']
- 自动记录每组超参数的训练损失、验证损失及准确率。
